{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11173548-325c-4cc6-977f-e4b608357f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b5be29-9ae3-493f-bcd0-058023332ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818cff22-4a50-4e6e-93b8-dc6c78a769cf",
   "metadata": {},
   "source": [
    "### Load csv data into a spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26fedaf2-c0d3-4dc7-b5e3-1ec3e680c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015 = spark.read.option(\"inferSchema\", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(r\"C:\\Users\\quang\\OneDrive\\Documents\\teaching\\big_data_fundamental\\week9\\lab_w9\\2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075659da-c8d0-4bc1-ae8a-d4fbf31891cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fbd69dd-b8fe-4ea6-a49f-a68088444182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', IntegerType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cdb22-7bb7-4852-a22f-1a939ffc8724",
   "metadata": {},
   "source": [
    "### Perform the take action on the DataFrame,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c3225c-461e-458c-996b-25e23016a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5081cb-745c-4700-9106-6284a7d4689e",
   "metadata": {},
   "source": [
    "### Check the explain plan of transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b21394-2564-4374-861c-f4b27132bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#48 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(count#48 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=80]\n",
      "      +- FileScan csv [DEST_COUNTRY_NAME#46,ORIGIN_COUNTRY_NAME#47,count#48] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/quang/OneDrive/Documents/teaching/big_data_fundamental/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.sort(\"count\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57085430-8855-4689-a679-4e5ddf88d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='Malta', ORIGIN_COUNTRY_NAME='United States', count=1),\n",
       " Row(DEST_COUNTRY_NAME='Saint Vincent and the Grenadines', ORIGIN_COUNTRY_NAME='United States', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Gibraltar', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.sort(\"count\").take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c41c5-1eb5-4f62-b30e-96f025c39b42",
   "metadata": {},
   "source": [
    "### DataFrames and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a4708c-df62-4d52-9317-9f52e9f5906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e326249-eee1-4b25-ad02-3421af107ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, count(1)\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5d5052a-517c-45a1-8ae3-3aed2dea285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameWay = flightData2015\\\n",
    ".groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    ".count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2dbc236-3968-4cac-b0e3-880fae7be103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#46, 200), ENSURE_REQUIREMENTS, [plan_id=108]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#46] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/quang/OneDrive/Documents/teaching/big_data_fundamental/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f16ff0b-34b7-439b-82f0-74456cb45808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#46, 200), ENSURE_REQUIREMENTS, [plan_id=121]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#46] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/quang/OneDrive/Documents/teaching/big_data_fundamental/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b402c-52d7-452b-aae7-e8a8ccff6af8",
   "metadata": {},
   "source": [
    "### Maximum number of flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c5cff8f-dca9-4a6e-a2c1-fb5edfa0c605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(count)=370002)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT max(count) from flight_data_2015\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd66858-a959-4e9d-90c7-0650f031ea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(count)=370002)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "flightData2015.select(max(\"count\")).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b77b05-4f95-4a84-bca9-f67e89455e84",
   "metadata": {},
   "source": [
    "### Top five destination countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add5913a-a1b1-4d77-8c27-8739041049d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxSql = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count) as destination_total\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY sum(count) DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "maxSql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdb6f2b6-c156-4837-97d2-31d37bc69d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "flightData2015\\\n",
    ".groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    ".sum(\"count\")\\\n",
    ".withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    ".sort(desc(\"destination_total\"))\\\n",
    ".limit(5)\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "188218c4-c5a2-4649-bbac-5d4400950fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#148L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#46,destination_total#148L])\n",
      "   +- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[sum(count#48)])\n",
      "      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#46, 200), ENSURE_REQUIREMENTS, [plan_id=291]\n",
      "         +- HashAggregate(keys=[DEST_COUNTRY_NAME#46], functions=[partial_sum(count#48)])\n",
      "            +- FileScan csv [DEST_COUNTRY_NAME#46,count#48] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/quang/OneDrive/Documents/teaching/big_data_fundamental/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015\\\n",
    ".groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    ".sum(\"count\")\\\n",
    ".withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    ".sort(desc(\"destination_total\"))\\\n",
    ".limit(5)\\\n",
    ".explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c564d-8bcf-48c8-8545-da3732bba6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
