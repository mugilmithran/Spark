{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151bcaad-7a26-4f0d-87ba-96374d7911d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3eb825-3b5f-428b-b07e-9d1f7cddc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901e8ff4-c116-446c-87d9-c83281290516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"2010-12-01.csv\")\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView(\"invoice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fd2986-19a9-4687-b4f7-f3576077c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185e4a6-09d3-4f85-9455-355c10bdc432",
   "metadata": {},
   "source": [
    "## Converting to Spark Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efcfecc8-e9ea-46cb-bc72-b2ccba6dc945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[5: int, five: string, 5.0: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5), lit(\"five\"), lit(5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150817a-ec58-4526-88bd-62b78d7d8cac",
   "metadata": {},
   "source": [
    "## Working with Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d110f9-6d07-4590-bebf-7db67778d520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------+\n",
      "|InvoiceNo|Description                        |\n",
      "+---------+-----------------------------------+\n",
      "|536365   |WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|536365   |WHITE METAL LANTERN                |\n",
      "|536365   |CREAM CUPID HEARTS COAT HANGER     |\n",
      "|536365   |KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|536365   |RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+---------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(\"InvoiceNo = 536365\").select(\"InvoiceNo\", \"Description\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ac3ebd-e1e8-4287-b519-09bd0003416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"InvoiceNo != 536365\").select(\"InvoiceNo\", \"Description\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf05e23-d05f-41b5-9745-b8a4ce8d1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"InvoiceNo <> 536365\").select(\"InvoiceNo\", \"Description\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f1275a-6f1a-4b8f-b168-282f0be6f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      NULL|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(df.Description, \"POSTAGE\") >= 1\n",
    "df.filter(df.StockCode.isin(\"DOT\")).where(priceFilter | descripFilter).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "051a2825-12bc-40f9-bed6-c16c925e66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      NULL|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT * FROM invoice WHERE StockCode in (\"DOT\") AND (UnitPrice > 600 OR instr(Description, \"POSTAGE\") >= 1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e6667d-183b-45c3-8193-db93fe4b5d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+-----------+\n",
      "|StockCode|unitPrice|   Description|isExpensive|\n",
      "+---------+---------+--------------+-----------+\n",
      "|      DOT|   569.77|DOTCOM POSTAGE|       true|\n",
      "|      DOT|   607.49|DOTCOM POSTAGE|       true|\n",
      "+---------+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DOTCodeFilter = col(\"StockCode\") == \"DOT\"\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(col(\"Description\"), \"POSTAGE\") >= 1\n",
    "df.withColumn(\"isExpensive\", DOTCodeFilter & (priceFilter | descripFilter))\\\n",
    ".filter(\"isExpensive\")\\\n",
    ".select(\"StockCode\", \"unitPrice\", \"Description\", \"isExpensive\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5114ceb0-f271-4e00-b2a1-30828db72a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+-----------+\n",
      "|StockCode|UnitPrice|   Description|isExpensive|\n",
      "+---------+---------+--------------+-----------+\n",
      "|      DOT|   569.77|DOTCOM POSTAGE|       true|\n",
      "|      DOT|   607.49|DOTCOM POSTAGE|       true|\n",
      "+---------+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"SELECT StockCode, UnitPrice, Description, \n",
    "(StockCode = 'DOT' AND (UnitPrice > 600 OR instr(Description, \"POSTAGE\") >= 1)) as isExpensive\n",
    "FROM invoice\n",
    "WHERE (StockCode = 'DOT' AND\n",
    "(UnitPrice > 600 OR instr(Description, \"POSTAGE\") >= 1))\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f18b4-3ad3-492b-bc56-916401f18092",
   "metadata": {},
   "source": [
    "## Working with Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ced494-553c-49ec-8416-615c7471ec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f0370b-14a3-424c-ac21-b734754c985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow\n",
    "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c65efa-9d43-42ff-86d9-49344e9bdafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"CustomerId\", \"(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3597788d-5793-49f1-a91d-af844bbf26b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|customerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT customerId, (POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity FROM invoice').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe628f0-54e1-4c00-8584-4d10fbd8e72c",
   "metadata": {},
   "source": [
    "### Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a97e713-bd04-4b8f-8488-e964762d11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36defbba-c9b2-48ac-ae0e-425e46c17903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|            3|             2|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT round(2.5), bround(2.5)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff27046-65c6-4907-8d81-8bf29ed80905",
   "metadata": {},
   "source": [
    "### Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4204572b-b331-4506-85bf-b3ec73df7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "|  count|             3108|              3108|                3098|              3108|              3108|              1968|          3108|\n",
      "|   mean| 536516.684944841|27834.304044117645|                NULL| 8.627413127413128| 4.151946589446603|15661.388719512195|          NULL|\n",
      "| stddev|72.89447869788873|17407.897548583845|                NULL|26.371821677029203|15.638659854603892|1854.4496996893627|          NULL|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|               0.0|           12431.0|     Australia|\n",
      "|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|            607.49|           18229.0|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c34015a2-67c7-4f5c-90e6-d9eb08bddaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "| StockCode_freqItems|  Quantity_freqItems|\n",
      "+--------------------+--------------------+\n",
      "|[22086, 21705, 72...|[200, 128, 23, 50...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.freqItems([\"StockCode\", \"Quantity\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d61c261b-43a3-4f97-94e4-2bad5b528258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|monotonically_increasing_id()|\n",
      "+-----------------------------+\n",
      "|                            0|\n",
      "|                            1|\n",
      "+-----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df.select(monotonically_increasing_id()).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9941a-0518-4653-afa4-d1dc923ed672",
   "metadata": {},
   "source": [
    "## Working with Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7f3289b-1a6b-4d5c-9a4a-25230ab779e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abe62481-4317-4489-be33-2f1c7ae6aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"Description\"),\n",
    "lower(col(\"Description\")),\n",
    "upper(lower(col(\"Description\")))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d16505b9-a30c-4b04-8f7f-e58cc2e586f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|cream cupid heart...|     CREAM CUPID HEART...|\n",
      "|KNITTED UNION FLA...|knitted union fla...|     KNITTED UNION FLA...|\n",
      "|RED WOOLLY HOTTIE...|red woolly hottie...|     RED WOOLLY HOTTIE...|\n",
      "|SET 7 BABUSHKA NE...|set 7 babushka ne...|     SET 7 BABUSHKA NE...|\n",
      "|GLASS STAR FROSTE...|glass star froste...|     GLASS STAR FROSTE...|\n",
      "|HAND WARMER UNION...|hand warmer union...|     HAND WARMER UNION...|\n",
      "|HAND WARMER RED P...|hand warmer red p...|     HAND WARMER RED P...|\n",
      "|ASSORTED COLOUR B...|assorted colour b...|     ASSORTED COLOUR B...|\n",
      "|POPPY'S PLAYHOUSE...|poppy's playhouse...|     POPPY'S PLAYHOUSE...|\n",
      "|POPPY'S PLAYHOUSE...|poppy's playhouse...|     POPPY'S PLAYHOUSE...|\n",
      "|FELTCRAFT PRINCES...|feltcraft princes...|     FELTCRAFT PRINCES...|\n",
      "|IVORY KNITTED MUG...|ivory knitted mug...|     IVORY KNITTED MUG...|\n",
      "|BOX OF 6 ASSORTED...|box of 6 assorted...|     BOX OF 6 ASSORTED...|\n",
      "|BOX OF VINTAGE JI...|box of vintage ji...|     BOX OF VINTAGE JI...|\n",
      "|BOX OF VINTAGE AL...|box of vintage al...|     BOX OF VINTAGE AL...|\n",
      "|HOME BUILDING BLO...|home building blo...|     HOME BUILDING BLO...|\n",
      "|LOVE BUILDING BLO...|love building blo...|     LOVE BUILDING BLO...|\n",
      "|RECIPE BOX WITH M...|recipe box with m...|     RECIPE BOX WITH M...|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT Description, lower(Description), Upper(lower(Description)) FROM invoice').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32f4b73f-8807-4dce-8bd0-863652f45522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6246491a-f185-4786-8e2a-b79c9297ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+----------+----------+\n",
      "| ltrim| rtrim| trim|        lp|        rp|\n",
      "+------+------+-----+----------+----------+\n",
      "|HELLO | HELLO|HELLO|     HELLO|HELLO     |\n",
      "|HELLO | HELLO|HELLO|     HELLO|HELLO     |\n",
      "+------+------+-----+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
    "trim(lit(\" HELLO \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 10, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966db03-88ae-4a8a-b06b-da0e4208be38",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45f6967d-af33-4c6e-afba-827c47e60739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0daf8bfb-500c-4f54-8492-0cf9d2515776",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f0af81d-a010-4383-a861-4a125fea334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Description').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd746217-ba57-4e5f-8616-e8ad3a07291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         color_clean|         Description|\n",
      "+--------------------+--------------------+\n",
      "|COLOR HANGING HEA...|WHITE HANGING HEA...|\n",
      "| COLOR METAL LANTERN| WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(regexp_replace(col(\"Description\"), regex_string, \"COLOR\").alias(\"color_clean\"),col(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "407c9c9e-d37c-4ad9-8a4a-8bd27e48cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         color_clean|         Description|\n",
      "+--------------------+--------------------+\n",
      "|COLOR HANGING HEA...|WHITE HANGING HEA...|\n",
      "| COLOR METAL LANTERN| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|CREAM CUPID HEART...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"SELECT\n",
    "regexp_replace(Description, 'BLACK|WHITE|RED|GREEN|BLUE', 'COLOR') as\n",
    "color_clean, Description\n",
    "FROM invoice\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1310a5b7-6d0a-43c9-9fdb-51498d91ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------+\n",
      "|translate(Description, LEET, 1337)|         Description|\n",
      "+----------------------------------+--------------------+\n",
      "|              WHI73 HANGING H3A...|WHITE HANGING HEA...|\n",
      "|               WHI73 M37A1 1AN73RN| WHITE METAL LANTERN|\n",
      "+----------------------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import translate\n",
    "df.select(translate(col(\"Description\"), \"LEET\", \"1337\"),col(\"Description\"))\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa05d80f-ae58-41a2-8725-8a31b2aa8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------+\n",
      "|translate(Description, LEET, 1337)|         Description|\n",
      "+----------------------------------+--------------------+\n",
      "|              WHI73 HANGING H3A...|WHITE HANGING HEA...|\n",
      "|               WHI73 M37A1 1AN73RN| WHITE METAL LANTERN|\n",
      "|              CR3AM CUPID H3AR7...|CREAM CUPID HEART...|\n",
      "+----------------------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT translate(Description, 'LEET', '1337'), Description FROM invoice\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "142a7837-976a-4a87-a115-bf339f1b86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|color_clean|         Description|\n",
      "+-----------+--------------------+\n",
      "|      WHITE|WHITE HANGING HEA...|\n",
      "|      WHITE| WHITE METAL LANTERN|\n",
      "+-----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "extract_str = \"(BLACK|WHITE|RED|GREEN|BLUE)\"\n",
    "df.select(regexp_extract(col(\"Description\"), extract_str, 1).alias(\"color_clean\"), col(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828cc0e-60ed-428c-95f0-ceb4ca825abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f02c9c1c-787e-474c-8056-3127374b796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|color|         Description|\n",
      "+-----+--------------------+\n",
      "|WHITE|WHITE HANGING HEA...|\n",
      "|WHITE| WHITE METAL LANTERN|\n",
      "|     |CREAM CUPID HEART...|\n",
      "|     |KNITTED UNION FLA...|\n",
      "|  RED|RED WOOLLY HOTTIE...|\n",
      "|     |SET 7 BABUSHKA NE...|\n",
      "|     |GLASS STAR FROSTE...|\n",
      "|     |HAND WARMER UNION...|\n",
      "|     |HAND WARMER RED P...|\n",
      "|     |ASSORTED COLOUR B...|\n",
      "|     |POPPY'S PLAYHOUSE...|\n",
      "|     |POPPY'S PLAYHOUSE...|\n",
      "|     |FELTCRAFT PRINCES...|\n",
      "|     |IVORY KNITTED MUG...|\n",
      "|     |BOX OF 6 ASSORTED...|\n",
      "|     |BOX OF VINTAGE JI...|\n",
      "|     |BOX OF VINTAGE AL...|\n",
      "|     |HOME BUILDING BLO...|\n",
      "|     |LOVE BUILDING BLO...|\n",
      "|     |RECIPE BOX WITH M...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"SELECT regexp_extract(Description, '(BLACK|WHITE|RED|GREEN|BLUE|)', 1) as color,\n",
    "Description\n",
    "FROM invoice\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ff31e5b-8b4d-443d-a0b2-4b99a48eee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |\n",
      "|RED WOOLLY HOTTIE WHITE HEART.    |\n",
      "+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "containsBlack = instr(col(\"Description\"), \"BLACK\") >= 1\n",
    "containsWhite = instr(col(\"Description\"), \"WHITE\") >= 1\n",
    "df.withColumn(\"hasSimpleColor\", containsBlack | containsWhite)\\\n",
    ".where(\"hasSimpleColor\")\\\n",
    ".select(\"Description\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f5eb7b2-2cf2-4825-8a82-b2ecf24de494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "|RED WOOLLY HOTTIE...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT Description FROM invoice WHERE instr(Description, 'BLACK') >= 1 OR instr(Description, 'WHITE') >= 1\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8eca4a32-4c1e-45ff-8297-3f35b6e1d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, locate\n",
    "simpleColors = [\"black\", \"white\", \"red\", \"green\", \"blue\"]\n",
    "def color_locator(column, color_string):\n",
    "    return locate(color_string.upper(), column)\\\n",
    "    .cast(\"boolean\")\\\n",
    "    .alias(\"is_\" + color_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50276c85-b0fb-4976-82cc-e0f3ee97b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns = [color_locator(df.Description, c) for c in simpleColors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a4a2f4ad-c033-4908-b22d-431b199c0368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+--------+-------+--------------------+\n",
      "|is_black|is_white|is_red|is_green|is_blue|         Description|\n",
      "+--------+--------+------+--------+-------+--------------------+\n",
      "|   false|    true| false|   false|  false|WHITE HANGING HEA...|\n",
      "|   false|    true| false|   false|  false| WHITE METAL LANTERN|\n",
      "|   false|    true|  true|   false|  false|RED WOOLLY HOTTIE...|\n",
      "|   false|   false|  true|   false|  false|HAND WARMER RED P...|\n",
      "|   false|   false|  true|   false|  false|RED COAT RACK PAR...|\n",
      "|   false|   false|  true|   false|  false|ALARM CLOCK BAKEL...|\n",
      "|   false|   false|  true|   false|  false|SET/2 RED RETROSP...|\n",
      "|   false|   false|  true|   false|  false|RED TOADSTOOL LED...|\n",
      "|   false|   false|  true|   false|  false|HAND WARMER RED P...|\n",
      "|   false|    true| false|   false|  false|WHITE HANGING HEA...|\n",
      "|   false|    true| false|   false|  false| WHITE METAL LANTERN|\n",
      "|   false|   false|  true|   false|  false|EDWARDIAN PARASOL...|\n",
      "|   false|    true| false|   false|  false|WOOD 2 DRAWER CAB...|\n",
      "|   false|    true| false|   false|  false|WOOD S/3 CABINET ...|\n",
      "|   false|    true| false|   false|  false|WOODEN PICTURE FR...|\n",
      "|   false|    true| false|   false|  false|WOODEN FRAME ANTI...|\n",
      "|   false|    true|  true|   false|  false|RED WOOLLY HOTTIE...|\n",
      "|   false|    true| false|   false|  false|WHITE HANGING HEA...|\n",
      "|   false|    true| false|   false|  false| WHITE METAL LANTERN|\n",
      "|   false|   false|  true|   false|  false|EDWARDIAN PARASOL...|\n",
      "+--------+--------+------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(selectedColumns + ['Description']).where(expr(\"is_white OR is_red\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8063dc-a5b5-4987-bc1e-73eff95171ee",
   "metadata": {},
   "source": [
    "## Working with Dates and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2abbeaa6-193b-495f-ad07-1cd3c5df2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = spark.range(10)\\\n",
    ".withColumn(\"today\", current_date())\\\n",
    ".withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a738e89e-ab48-4f07-8ab3-cb196d284f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2767794f-6dbf-44d9-aa4a-c5318cf496c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|     today|                 now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2023-11-17|2023-11-17 19:02:...|\n",
      "|  1|2023-11-17|2023-11-17 19:02:...|\n",
      "|  2|2023-11-17|2023-11-17 19:02:...|\n",
      "|  3|2023-11-17|2023-11-17 19:02:...|\n",
      "|  4|2023-11-17|2023-11-17 19:02:...|\n",
      "|  5|2023-11-17|2023-11-17 19:02:...|\n",
      "|  6|2023-11-17|2023-11-17 19:02:...|\n",
      "|  7|2023-11-17|2023-11-17 19:02:...|\n",
      "|  8|2023-11-17|2023-11-17 19:02:...|\n",
      "|  9|2023-11-17|2023-11-17 19:02:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "603b1f1f-1ec0-40fc-bf7d-0178037fc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15cecd99-35ba-42ec-bb7f-1fb262062233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2023-11-12|        2023-11-22|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b923612-7341-4b2a-ba01-beea2ed4b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "|        2023-11-12|        2023-11-22|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT date_sub(today, 5), date_add(today, 5) FROM dateTable').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aff83a0e-01ce-4ae1-b0f5-e1f76169c511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+----------+\n",
      "| id|     today|                 now|  week_ago|\n",
      "+---+----------+--------------------+----------+\n",
      "|  0|2023-11-17|2023-11-17 19:05:...|2023-11-10|\n",
      "|  1|2023-11-17|2023-11-17 19:05:...|2023-11-10|\n",
      "+---+----------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6c70794c-d608-4be2-beb3-456db74d1d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7)).select(datediff(col(\"week_ago\"), col(\"today\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec2aae99-26f8-49e4-9f58-3863d7007954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                           -12.0|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(\n",
    "to_date(lit(\"2023-01-01\")).alias(\"start\"),\n",
    "to_date(lit(\"2024-01-01\")).alias(\"end\"))\\\n",
    ".select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c58db8d9-1848-4003-9158-b47342795bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------------------------+--------------------------------+\n",
      "|to_date(2023-01-01)|months_between(2023-01-01, 2024-01-01, true)|datediff(2023-01-01, 2024-01-01)|\n",
      "+-------------------+--------------------------------------------+--------------------------------+\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "|         2023-01-01|                                       -12.0|                            -365|\n",
      "+-------------------+--------------------------------------------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"SELECT to_date('2023-01-01'), months_between('2023-01-01', '2024-01-01'),\n",
    "datediff('2023-01-01', '2024-01-01')\n",
    "FROM dateTable\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "04bfd7b1-9b4f-4365-830e-41c648abff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|to_date(date)|\n",
      "+-------------+\n",
      "|   2023-01-01|\n",
      "|   2023-01-01|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, lit\n",
    "spark.range(5).withColumn(\"date\", lit(\"2023-01-01\")).select(to_date(col(\"date\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d5690f7b-b05b-449d-8bb0-f72985888a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|to_date(2023-32-12)|to_date(2023-12-11)|\n",
      "+-------------------+-------------------+\n",
      "|               NULL|         2023-12-11|\n",
      "+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(to_date(lit(\"2023-32-12\")),to_date(lit(\"2023-12-11\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2828639e-0f96-4ac4-b8a9-04c5a6a9eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFormat = \"yyyy-dd-MM\"\n",
    "cleanDateDF = spark.range(1).select(\n",
    "to_date(lit(\"2023-12-11\"), dateFormat).alias(\"date\"),\n",
    "to_date(lit(\"2023-20-12\"), dateFormat).alias(\"date2\"))\n",
    "cleanDateDF.createOrReplaceTempView(\"dateTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b683deb4-5abb-4e9b-a297-04e94439a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2023-11-12|2023-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanDateDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "159b88b1-adff-4f91-8f64-969a02f2af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|to_timestamp(date, yyyy-dd-MM)|\n",
      "+------------------------------+\n",
      "|           2023-11-12 00:00:00|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "cleanDateDF.select(to_timestamp(col(\"date\"), dateFormat)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "465da593-92dc-49f3-81a1-e3200d34fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|to_timestamp(date, yyyy-dd-MM)|\n",
      "+------------------------------+\n",
      "|           2023-11-12 00:00:00|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanDateDF.select(to_timestamp(col(\"date\"), 'yyyy-dd-MM')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bc8d66d6-c90a-4be5-99c1-fe98ff11e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------------------------+\n",
      "|to_timestamp(date, yyyy-dd-MM)|to_timestamp(date2, yyyy-dd-MM)|\n",
      "+------------------------------+-------------------------------+\n",
      "|           2023-11-12 00:00:00|            2023-12-20 00:00:00|\n",
      "+------------------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT to_timestamp(date, 'yyyy-dd-MM'), to_timestamp(date2, 'yyyy-dd-MM') FROM dateTable2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f596d-0ac5-44c5-bfbd-24d9474d4320",
   "metadata": {},
   "source": [
    "## Working with Nulls in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606fdde-195c-4e7d-86e7-4172558beca4",
   "metadata": {},
   "source": [
    "### drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "14920f9e-3091-4dd2-b7dc-d2c159002a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "   StructField(\"name\", StringType(), True),\n",
    "   StructField(\"age\", IntegerType(), True)])\n",
    "df2 = spark.createDataFrame([('alice', 20), ('bob', None), ('john', 25), (None, None)], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fcf8baca-7fa8-49d0-a43f-e70e939e12fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| name| age|\n",
      "+-----+----+\n",
      "|alice|  20|\n",
      "|  bob|NULL|\n",
      "| john|  25|\n",
      "| NULL|NULL|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bec0432a-eebe-40a0-af94-f64b9753a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|alice| 20|\n",
      "| john| 25|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f4b8a465-fcbd-41fc-9f32-90defd6c9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| name| age|\n",
      "+-----+----+\n",
      "|alice|  20|\n",
      "|  bob|NULL|\n",
      "| john|  25|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fa85c1a1-7eb9-4875-a52f-0b3d03f52e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|alice| 20|\n",
      "| john| 25|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(\"all\", subset=[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c708a6-a390-4185-9b82-b910d325df96",
   "metadata": {},
   "source": [
    "### fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a55aa723-8cd6-4ff2-b540-126d77f056e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|  name| age|\n",
      "+------+----+\n",
      "| alice|  20|\n",
      "|   bob|NULL|\n",
      "|  john|  25|\n",
      "|python|NULL|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.fill(\"python\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "15de9eb6-1309-4f87-bc2c-36968ed1057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|alice| 20|\n",
      "|  bob| 99|\n",
      "| john| 25|\n",
      "| NULL| 99|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.fill(99).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ebd1b4-0b59-4481-9165-7aac06b51401",
   "metadata": {},
   "source": [
    "## Working with Complex Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7bc9b-caf0-40d6-8243-9cbb4078d23d",
   "metadata": {},
   "source": [
    "### Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "68dafd76-4bd9-494d-ae20-08559f2855de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6a62e1ae-8b33-43b2-b7a0-8eaddd3c7faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.Description\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7a3039de-7bba-4b07-b3ac-01d4ca9f509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| complex.Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(col(\"complex\").getField(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9b5e4705-31d9-4b11-b2d4-1f8155c4b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|         Description|InvoiceNo|\n",
      "+--------------------+---------+\n",
      "|WHITE HANGING HEA...|   536365|\n",
      "| WHITE METAL LANTERN|   536365|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.*\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0c486-563b-487e-96e1-a168b2578523",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5db53c0d-2d65-4656-854b-cf7cfb0fa933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [WHITE, HANGING, ...|\n",
      "|     [WHITE, METAL, LA...|\n",
      "+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df.select(split(col(\"Description\"), \" \")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f33c110e-abaf-40b6-b821-9f67b873875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [WHITE, HANGING, ...|\n",
      "|     [WHITE, METAL, LA...|\n",
      "|     [CREAM, CUPID, HE...|\n",
      "+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT split(Description, ' ') FROM invoice\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e198608d-b987-45a9-a587-aa0e902d544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|array_col[0]|\n",
      "+------------+\n",
      "|       WHITE|\n",
      "|       WHITE|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\\\n",
    ".selectExpr(\"array_col[0]\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3352867f-4acc-4185-ba6f-b5404c7f1446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|split(Description,  , -1)[0]|\n",
      "+----------------------------+\n",
      "|                       WHITE|\n",
      "|                       WHITE|\n",
      "+----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT split(Description, ' ')[0] FROM invoice\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9d163623-e9b1-4ac1-a166-145cbc2b1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------------+\n",
      "|         Description|size(split(Description,  , -1))|\n",
      "+--------------------+-------------------------------+\n",
      "|WHITE HANGING HEA...|                              5|\n",
      "| WHITE METAL LANTERN|                              3|\n",
      "+--------------------+-------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "df.select(\"Description\", size(split(col(\"Description\"), \" \"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cd9854ef-47db-455a-b1c2-ba212065c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|array_contains(split(Description,  , -1), WHITE)|\n",
      "+------------------------------------------------+\n",
      "|                                            true|\n",
      "|                                            true|\n",
      "+------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.select(array_contains(split(col(\"Description\"), \" \"), \"WHITE\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f6fd6-af09-4982-8df8-f0969ba6c039",
   "metadata": {},
   "source": [
    "### explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "23092c6b-4891-41c1-bf6c-68c5bad22579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------+\n",
      "|         Description|InvoiceNo|            splitted|exploded|\n",
      "+--------------------+---------+--------------------+--------+\n",
      "|WHITE HANGING HEA...|   536365|[WHITE, HANGING, ...|   WHITE|\n",
      "|WHITE HANGING HEA...|   536365|[WHITE, HANGING, ...| HANGING|\n",
      "|WHITE HANGING HEA...|   536365|[WHITE, HANGING, ...|   HEART|\n",
      "|WHITE HANGING HEA...|   536365|[WHITE, HANGING, ...| T-LIGHT|\n",
      "|WHITE HANGING HEA...|   536365|[WHITE, HANGING, ...|  HOLDER|\n",
      "| WHITE METAL LANTERN|   536365|[WHITE, METAL, LA...|   WHITE|\n",
      "| WHITE METAL LANTERN|   536365|[WHITE, METAL, LA...|   METAL|\n",
      "| WHITE METAL LANTERN|   536365|[WHITE, METAL, LA...| LANTERN|\n",
      "|CREAM CUPID HEART...|   536365|[CREAM, CUPID, HE...|   CREAM|\n",
      "|CREAM CUPID HEART...|   536365|[CREAM, CUPID, HE...|   CUPID|\n",
      "|CREAM CUPID HEART...|   536365|[CREAM, CUPID, HE...|  HEARTS|\n",
      "|CREAM CUPID HEART...|   536365|[CREAM, CUPID, HE...|    COAT|\n",
      "|CREAM CUPID HEART...|   536365|[CREAM, CUPID, HE...|  HANGER|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...| KNITTED|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...|   UNION|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...|    FLAG|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...|     HOT|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...|   WATER|\n",
      "|KNITTED UNION FLA...|   536365|[KNITTED, UNION, ...|  BOTTLE|\n",
      "|RED WOOLLY HOTTIE...|   536365|[RED, WOOLLY, HOT...|     RED|\n",
      "+--------------------+---------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    ".withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    ".select(\"Description\", \"InvoiceNo\", \"splitted\", \"exploded\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a4319-dfed-42ef-a21c-b95403d473f6",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7545c255-f19f-4ccd-a3eb-0df57d71b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         complex_map|\n",
      "+--------------------+\n",
      "|{WHITE HANGING HE...|\n",
      "|{WHITE METAL LANT...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map\n",
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "81622770-a616-452f-86bf-48835d786da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|complex_map[WHITE METAL LANTERN]|\n",
      "+--------------------------------+\n",
      "|                            NULL|\n",
      "|                          536365|\n",
      "+--------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\")).selectExpr(\"complex_map['WHITE METAL LANTERN']\").show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
