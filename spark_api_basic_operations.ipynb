{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b84cae6-05c6-401a-989a-11328150d3eb",
   "metadata": {},
   "source": [
    "## Overview of Structured API Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ffb84-9872-4811-b49e-24b5feb16f2b",
   "metadata": {},
   "source": [
    "1. Write DataFrame/Dataset/SQL Code.\r\n",
    "2. If valid code, Spark converts this to a Logical Plan.\r\n",
    "3. Spark transforms this Logical Plan to a Physical Plan, checking for optimizations along\r\n",
    "the way.\r\n",
    "4. Spark then executes this Physical Plan (RDD manipulations) on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf0395-b75b-4b36-9bb4-15ea204e5364",
   "metadata": {},
   "source": [
    "![Catalyst Optimizer](ct.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76ffcb-6de0-42a2-819e-b4f5c528614c",
   "metadata": {},
   "source": [
    "### Logical Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb6370-1ea8-4867-afe2-1629405c4bbe",
   "metadata": {},
   "source": [
    "This logical plan only represents a set of abstract transformations that do not refer to executors or\r\n",
    "drivers, it’s purely to convert the user’s set of expressions into the most optimized version. It\r\n",
    "does this by converting user code into an unresolved logical plan. This plan is unresolved\r\n",
    "because although your code might be valid, the tables or columns that it refers to might or might\r\n",
    "not exist. Spark uses the catalog, a repository of all table and DataFrame information, to resolve\r\n",
    "columns and tables in the analyzer. The analyzer might reject the unresolved logical plan if the\r\n",
    "required table or column name does not exist in the catalog. If the analyzer can resolve it, the\r\n",
    "result is passed through the Catalyst Optimizer, a collection of rules that attempt to optimize the\r\n",
    "logical plan by pushing down predicates or selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c44287-c030-4934-affa-332cbeb66176",
   "metadata": {},
   "source": [
    "![Logical Plan](lp.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b098d-cce6-4c18-aecb-7dd524e02445",
   "metadata": {},
   "source": [
    "### Physical Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bc2d6-c3bd-41f7-a0f9-908e3bf74d0c",
   "metadata": {},
   "source": [
    "After successfully creating an optimized logical plan, Spark then begins the physical planning process. The physical plan, often called a Spark plan, specifies how the logical plan will execute on the cluster by generating different physical execution strategies and comparing them through a cost model. An example of the cost comparison might be choosing how to perform a given join by looking at the physical attributes of a given table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2b09c-23a1-4ffb-b2e4-e675839e417a",
   "metadata": {},
   "source": [
    "![Physical Plan](pl.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705f0b3-114d-4906-b018-149a45da1e3a",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b24cfc-097a-4309-876c-780165657011",
   "metadata": {},
   "source": [
    "Upon selecting a physical plan, Spark runs all of this code over RDDs, the lower-level\r\n",
    "programming interface of Spark (which we cover in Part III). Spark performs further\r\n",
    "optimizations at runtime, generating native Java bytecode that can remove entire tasks or stages\r\n",
    "during execution. Finally the result is returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7df37-830d-4190-b091-b2b76f3edd9b",
   "metadata": {},
   "source": [
    "## Basic Structured Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a022d0-8bc2-4573-a4ff-59b7d13ba7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b04496-6fdf-4c4b-85f1-35893a172a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").options(header=True).csv(\"2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3559ec9-4319-45e8-a44e-34e2132b8c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fe72e-285e-46d1-a4e6-7a110d46a231",
   "metadata": {},
   "source": [
    "### Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "614a46f0-0837-4b9a-b181-bbb00a46780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', IntegerType(), True)])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aea6715a-9690-44cd-8600-385315b6b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', IntegerType(), True)])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually define schema\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "schema = StructType([\n",
    "StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    "StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    "StructField(\"count\", IntegerType())\n",
    "])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cee71f37-c588-41b6-b379-12ce3cf49cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header=True).schema(schema).csv(\"2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9c744570-39d1-40a0-a937-99bce3239dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67aded9-1615-4ade-9b37-3630d8f0fb4d",
   "metadata": {},
   "source": [
    "### Columns and Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b86ea-95e6-4938-9b95-4817e19a93e9",
   "metadata": {},
   "source": [
    "#### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3943f8-b9ab-4a9f-bc64-79f34a8a376c",
   "metadata": {},
   "source": [
    "Columns in Spark are similar to columns in a spreadsheet, R dataframe, or pandas DataFrame.\r\n",
    "You can select, manipulate, and remove columns from DataFrames and these operations are\r\n",
    "represented as expressions.\r\n",
    "To Spark, columns are logical constructions that simply represent a value computed on a perrecord\r\n",
    "basis by means of an expression. This means that to have a real value for a column, we\r\n",
    "need to have a row; and to have a row, we need to have a DataFrame. You cannot manipulate an\r\n",
    "individual column outside the context of a DataFrame; you must use Spark transformations\r\n",
    "within a DataFrame to modify the contents of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d98c21-3b28-420a-b50a-07bb7879f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab6293cd-92ec-4c3f-b215-f438381d9305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'bigdata'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('bigdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94825985-e29a-48bc-beae-4d8cec2f1cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'spark'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column('spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cfc17-f2d2-484a-be62-e05fea093b6e",
   "metadata": {},
   "source": [
    "#### Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85636b9a-b303-41fb-beee-84bf4e21c893",
   "metadata": {},
   "source": [
    "- Columns are just expressions.\r",
    "- \n",
    "Columns and transformations of those columns compile to the same logical plan as\r\n",
    "parsed expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c16c6ddf-3b6e-410d-8158-8ca74c5e4e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'((((bigdata + 24) * 3) - 88) < spark)'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((col(\"bigdata\") + 24) * 3) - 88) < col(\"spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6aca4d3d-cb33-4523-8336-d5fd8667a673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'((((bigdata + 24) * 3) - 88) < spark)'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "expr(\"((bigdata + 24) * 3 - 88) < spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79128ccb-83e8-49e4-b1b1-7f83abedba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataframe columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a85058-3250-4d62-ad8e-a4b3c1010c54",
   "metadata": {},
   "source": [
    "### Records and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9194f485-f19a-4917-aed9-51ba46dc32dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aaccf4-2c38-4ebc-a764-b496496e574a",
   "metadata": {},
   "source": [
    "#### Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d502d1a-5b09-4a42-adaf-2c742ec952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "myRow = Row(\"Hello\", None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3dae8298-8c6c-4187-96ed-5719a026d668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797c95c-dd84-40df-9993-5f795d221824",
   "metadata": {},
   "source": [
    "### DataFrame Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a61bfe-a253-4491-857f-4a2c432cfeef",
   "metadata": {},
   "source": [
    "- We can add rows or columns\n",
    "- We can remove rows or columns\n",
    "- We can transform a row into a column (or vice versa)\n",
    "- We can change the order of rows based on the values in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2b7ea-7687-46ac-8541-40b6a3f11208",
   "metadata": {},
   "source": [
    "#### Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b81bd0d3-6aac-4792-b4ed-e7b5482238b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+\n",
      "|   h1|  h2| h3|\n",
      "+-----+----+---+\n",
      "|Hello|NULL|  1|\n",
      "|Spark|data|  3|\n",
      "+-----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "schema = StructType([\n",
    "StructField(\"h1\", StringType(), True),\n",
    "StructField(\"h2\", StringType(), True),\n",
    "StructField(\"h3\", LongType(), False)\n",
    "])\n",
    "Row1 = Row(\"Hello\", None, 1)\n",
    "Row2 = Row(\"Spark\", 'data', 3)\n",
    "mdf = spark.createDataFrame([Row1, Row2], schema)\n",
    "mdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8a160-ecd9-4fb5-9324-522deee7f0c5",
   "metadata": {},
   "source": [
    "#### select and selectExpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb843fac-a659-4529-ae33-e232bee59a3c",
   "metadata": {},
   "source": [
    "select and selectExpr allow you to do the DataFrame equivalent of SQL queries on a table of\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3274f669-e8ad-402a-87eb-9d6f819b2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header=True, inferSchema=True).csv(\"2015-summary.csv\")\n",
    "df.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1b8be844-35d0-4ba0-b47a-88c642548ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "85de65f4-d2ac-4e97-bdaf-4b69147fe3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT DEST_COUNTRY_NAME FROM flights LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9faaac7e-9598-4ad7-9256-725136d4db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.select('DEST_COUNTRY_NAME').limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fad4429a-70ac-478e-9959-c3f5a88bb724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----------------+\n",
      "|            Romania|    United States|\n",
      "|            Croatia|    United States|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME FROM flights LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eec0f87e-c743-46ce-aef7-dca5f909bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----------------+\n",
      "|            Romania|    United States|\n",
      "|            Croatia|    United States|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.select('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME').limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67b58e12-660f-4634-bfd7-650483a7be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----------------+\n",
      "|            Romania|    United States|\n",
      "|            Croatia|    United States|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME']).limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0c4851c4-6383-43a6-8854-d8d5297216a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+\n",
      "|ORIGIN_COUNTRY_NAME|   DEST_COUNTRY_NAME|count|\n",
      "+-------------------+--------------------+-----+\n",
      "|            Romania|       United States|   15|\n",
      "|            Croatia|       United States|    1|\n",
      "|            Ireland|       United States|  344|\n",
      "|      United States|               Egypt|   15|\n",
      "|              India|       United States|   62|\n",
      "|          Singapore|       United States|    1|\n",
      "|            Grenada|       United States|   62|\n",
      "|      United States|          Costa Rica|  588|\n",
      "|      United States|             Senegal|   40|\n",
      "|      United States|             Moldova|    1|\n",
      "|       Sint Maarten|       United States|  325|\n",
      "|   Marshall Islands|       United States|   39|\n",
      "|      United States|              Guyana|   64|\n",
      "|      United States|               Malta|    1|\n",
      "|      United States|            Anguilla|   41|\n",
      "|      United States|             Bolivia|   30|\n",
      "|           Paraguay|       United States|    6|\n",
      "|      United States|             Algeria|    4|\n",
      "|      United States|Turks and Caicos ...|  230|\n",
      "|          Gibraltar|       United States|    1|\n",
      "+-------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('ORIGIN_COUNTRY_NAME'), column('DEST_COUNTRY_NAME'), 'count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1a82a866-9f72-4f5e-b0bc-f6db4dc849a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|departure|      arrival|\n",
      "+---------+-------------+\n",
      "|  Romania|United States|\n",
      "|  Croatia|United States|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change column name\n",
    "# SQL\n",
    "spark.sql('SELECT ORIGIN_COUNTRY_NAME as departure, DEST_COUNTRY_NAME as arrival FROM flights LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eac1db79-099f-40aa-adb7-e45e5ebb089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|departure|      arrival|\n",
      "+---------+-------------+\n",
      "|  Romania|United States|\n",
      "|  Croatia|United States|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.select(expr('ORIGIN_COUNTRY_NAME as departure'), expr('DEST_COUNTRY_NAME as arrival')).limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fa943a53-0a24-4b54-9e7e-53b28310b298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|departure|      arrival|\n",
      "+---------+-------------+\n",
      "|  Romania|United States|\n",
      "|  Croatia|United States|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('ORIGIN_COUNTRY_NAME as departure', 'DEST_COUNTRY_NAME as arrival').limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f4d8777b-5dd8-45a3-9f59-f5234e35eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.selectExpr(\n",
    "\"*\", # all original columns\n",
    "\"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c8c7855-cd2c-4a8a-acca-9204e8f04039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT f.*, f.DEST_COUNTRY_NAME = f.ORIGIN_COUNTRY_NAME as withinCountry FROM flights f LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8b902f26-266e-4086-b28a-6aa3538d331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|  avg_count|distinct_count|\n",
      "+-----------+--------------+\n",
      "|1770.765625|           132|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.selectExpr(\"avg(count) as avg_count\", \"count(distinct(DEST_COUNTRY_NAME)) distinct_count\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "48e0b25c-cab9-479c-bbff-356c3001df84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|  avg_count|distinct_count|\n",
      "+-----------+--------------+\n",
      "|1770.765625|           132|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT avg(count) as avg_count, count(distinct(DEST_COUNTRY_NAME)) as distinct_count FROM flights LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be166e-822f-4d55-a1be-36aaa2e49227",
   "metadata": {},
   "source": [
    "#### Converting to Spark Types (Literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ebce4f2b-a9a6-4113-83ae-b2b2fc058750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "from pyspark.sql.functions import lit\n",
    "df.select(expr(\"*\"), lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "556c2c25-b57b-4bdb-884e-e2bcf1dc7155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT f.*, 1 as One FROM flights f LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0362854e-8f57-443e-94fe-a23c5231331d",
   "metadata": {},
   "source": [
    "#### Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "06c1e462-c1ff-43ec-b2a2-a5ad0095fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d1d34f7c-2c3e-4876-b2b3-b8fae756e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT *, 1 as numberOne FROM flights LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "541a0811-4cf9-41b7-9fd2-d2e4bc06332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5f320-bfc0-4dec-a139-1b09ab012426",
   "metadata": {},
   "source": [
    "#### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "66976319-7644-4358-843a-323afe77e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|             arrival|       departure|count|\n",
      "+--------------------+----------------+-----+\n",
      "|       United States|         Romania|   15|\n",
      "|       United States|         Croatia|    1|\n",
      "|       United States|         Ireland|  344|\n",
      "|               Egypt|   United States|   15|\n",
      "|       United States|           India|   62|\n",
      "|       United States|       Singapore|    1|\n",
      "|       United States|         Grenada|   62|\n",
      "|          Costa Rica|   United States|  588|\n",
      "|             Senegal|   United States|   40|\n",
      "|             Moldova|   United States|    1|\n",
      "|       United States|    Sint Maarten|  325|\n",
      "|       United States|Marshall Islands|   39|\n",
      "|              Guyana|   United States|   64|\n",
      "|               Malta|   United States|    1|\n",
      "|            Anguilla|   United States|   41|\n",
      "|             Bolivia|   United States|   30|\n",
      "|       United States|        Paraguay|    6|\n",
      "|             Algeria|   United States|    4|\n",
      "|Turks and Caicos ...|   United States|  230|\n",
      "|       United States|       Gibraltar|    1|\n",
      "+--------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"arrival\")\\\n",
    ".withColumnRenamed(\"ORIGIN_COUNTRY_NAME\", \"departure\")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bf15b-81b6-4928-8087-274ee12ad5ea",
   "metadata": {},
   "source": [
    "#### Case Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fb9af-6158-44bd-95f9-3e962baad22f",
   "metadata": {},
   "source": [
    "By default Spark is case insensitive; however, you can make Spark case sensitive by setting the\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1b2e1b-8454-4942-815a-dbfff5be849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.config('spark.sql.caseSensitive', 'true').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1d78c2-1d91-4109-a67f-5ad9df568787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|dest_country_name|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('dest_country_name').limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50a665-8757-4a2e-96d3-9770cd98f7e4",
   "metadata": {},
   "source": [
    "#### Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "955c7560-1b15-4d5a-b2a1-9ddf6d77d092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee72eda-a546-4a05-9a3a-33167444ee2c",
   "metadata": {},
   "source": [
    "#### Changing a Column’s Type (cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73397a86-f899-4513-bac0-4c1bfc0d5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"count2\", col(\"count\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d998c6-24fd-4392-aa4d-5f8f1f6f6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int, count2: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('SELECT *, cast(count as long) AS count2 FROM flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8337a5-ed3f-49c5-8f01-fe6dbdecc5af",
   "metadata": {},
   "source": [
    "#### Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55018c78-f79f-40b6-b790-c1ae6f528530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.filter(col(\"count\") < 2).show(2)\n",
    "df.where(\"count < 2\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16c79477-86a4-490d-bf55-162af58d7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT * FROM flights WHERE count < 2 LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abcd127c-40c0-459d-8708-eedf354d0b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adbcfc7c-af01-4390-95ed-7cb5ad0aa131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT * FROM flights WHERE count < 2 AND ORIGIN_COUNTRY_NAME != \"Croatia\" LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578b500-bc91-46fb-b031-91d3c9313409",
   "metadata": {},
   "source": [
    "#### Getting Unique Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e7a7b05-6404-4261-8aac-2dcb044f3397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d63b24b4-a0cc-438b-9e2d-f4e6329e905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  256|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT COUNT(DISTINCT(ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME)) as count FROM flights').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f422164-5e8b-427a-bc02-f4c235345226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06b2413a-f626-400b-95f2-35eea3760e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  125|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT COUNT(DISTINCT ORIGIN_COUNTRY_NAME) as count FROM flights').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93c76b-9aac-4bdb-bed0-896c8036f6f0",
   "metadata": {},
   "source": [
    "#### Concatenating and Appending Rows (Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd32cd59-23dd-4093-932c-032344d57fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32af2f20-b0b4-4f90-94a3-9fc26f9b0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "newRows = [\n",
    "Row(\"New Country\", \"Other Country\", 5),\n",
    "Row(\"New Country 2\", \"Other Country 3\", 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e41161d-e192-450b-bf0a-387c40b79288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row('New Country', 'Other Country', 5)>,\n",
       " <Row('New Country 2', 'Other Country 3', 1)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1ce3779-89df-4166-800d-c77639dae65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = spark.createDataFrame(newRows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ddfe44f-713c-4130-b067-5e295c329c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Country|      Other Country|    5|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d93230d-d3ea-4b7c-bba8-cda280d2038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Zealand|      United States|  111|\n",
      "| Papua New Guinea|      United States|    3|\n",
      "|    New Caledonia|      United States|    1|\n",
      "|      New Country|      Other Country|    5|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(newDF).where(col('DEST_COUNTRY_NAME').like('%New%')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76b7b82d-5e89-4a82-8a9d-17e316adaf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Zealand|      United States|  111|\n",
      "| Papua New Guinea|      United States|    3|\n",
      "|    New Caledonia|      United States|    1|\n",
      "|      New Country|      Other Country|    5|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(newDF).where(col('DEST_COUNTRY_NAME').contains('New')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deabcff-9380-4122-a882-80adafed2bfe",
   "metadata": {},
   "source": [
    "#### Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be2550d7-30be-4efa-be1a-c447cb06527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abc5e217-5b9a-4c61-a725-588627d20605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cb92057-ab91-43bf-b3a8-7d47303ea633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ef0f89b-a21e-4b69-8303-70537a93b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc8ae2bf-69a3-4665-9389-d3f6a13b7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Moldova|      United States|    1|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(expr(\"count desc\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1733d0f7-a869-4fbe-9821-4abca13ec5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"count\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "216e5b61-47ac-4cb4-8199-16f993705d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql('SELECT * FROM flights ORDER BY count DESC, DEST_COUNTRY_NAME ASC LIMIT 2').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7db46-576a-45dc-a04a-7cbdf3f981f5",
   "metadata": {},
   "source": [
    "#### Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc624b98-88f6-4717-971a-daf8f7b910ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa7a79-aaf3-49ba-9084-6a31d231605a",
   "metadata": {},
   "source": [
    "#### Collecting Rows to the Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18b7bbf8-d6a1-462d-94c9-0003f1035cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectDF = df.limit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19f9f6e0-e4af-4dd1-b0fd-5bbea1463b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF.take(5) # take works with an Integer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7db52c7-aae7-4f5f-8f1f-faacc1a09f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collectDF.show() # this prints it out nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbaaea33-a906-4621-9604-889457668e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collectDF.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b7c7a3a-af27-4810-b43f-74ab45958e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Grenada', count=62),\n",
       " Row(DEST_COUNTRY_NAME='Costa Rica', ORIGIN_COUNTRY_NAME='United States', count=588),\n",
       " Row(DEST_COUNTRY_NAME='Senegal', ORIGIN_COUNTRY_NAME='United States', count=40),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74fdf0-8c06-4826-923f-5fe7a3e3b568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
