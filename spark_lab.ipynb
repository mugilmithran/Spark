{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96e8d0ff-c401-471b-8835-ecba9d09b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\vijay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\vijay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c6d6c6-eee2-46e3-bde8-060ed84f59b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pysprk is installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyspark\n",
    "    print(\"pysprk is installed\")\n",
    "except ImportError as e:\n",
    "    print(\"pyspark is not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840b1223-7b1d-4d74-818e-bb35d4a97e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary package for Spark Session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75684e54-c09b-4a95-b9b3-3d6efed806e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions for DataFrame operations\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7be42e1-c472-4f76-9818-03ea66ca8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301c657a-d348-4059-99c1-6a9ae98eecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Session\n",
    "# SparkSession is the entry point for spark applications. It allows you to run SQL queries on database tables.\n",
    "spark = SparkSession.builder.appName(\"VerifyInstallation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1791061b-0030-41d8-8d1b-cd49f1924e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark created successfully. <pyspark.sql.session.SparkSession object at 0x000001E25D9F6720>\n"
     ]
    }
   ],
   "source": [
    "# To check whether spark is created.\n",
    "print(\"Spark created successfully.\", spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e8d338-72ea-4b7e-b750-001e4b59493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba415044-8dac-4c49-9da8-28229284f0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|user_id|transaction_amount|\n",
      "+-------+------------------+\n",
      "|      5|            545.92|\n",
      "|     98|            386.07|\n",
      "|     30|            577.02|\n",
      "|     14|            479.49|\n",
      "|     34|            834.78|\n",
      "|     29|            531.64|\n",
      "|     72|            275.41|\n",
      "|     79|            272.48|\n",
      "|     38|            365.55|\n",
      "|     47|            902.76|\n",
      "|      8|            816.28|\n",
      "|     82|            610.81|\n",
      "|     29|             68.13|\n",
      "|     34|            568.34|\n",
      "|     26|            367.73|\n",
      "|     98|             118.9|\n",
      "|     54|            179.38|\n",
      "|     78|             31.64|\n",
      "|     43|            743.28|\n",
      "|     61|             667.6|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98295194-5ed0-4bb3-82c5-506ddc022133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Operations: Perform operations like filtering, selecting, grouping, and aggregating.\n",
    "\n",
    "# Select specific columns\n",
    "df_selected = df.select(\"user_id\", \"transaction_amount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f55cd6-9f81-4c15-9a5b-36546d0f376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|user_id|sum_transaction_amount|\n",
      "+-------+----------------------+\n",
      "|     31|    2734.0200000000004|\n",
      "|     85|               4844.78|\n",
      "|     65|               5884.35|\n",
      "|     53|               4328.05|\n",
      "|     78|               4119.06|\n",
      "|     34|               8613.88|\n",
      "|     81|               2671.48|\n",
      "|     28|     9781.330000000002|\n",
      "|     76|               5682.46|\n",
      "|     26|               5087.62|\n",
      "|     27|               5184.84|\n",
      "|     44|                2529.5|\n",
      "|     12|     4981.290000000001|\n",
      "|     91|    3996.2000000000007|\n",
      "|     22|               6635.94|\n",
      "|     93|     7866.179999999999|\n",
      "|     47|    1936.5099999999998|\n",
      "|      1|               5392.26|\n",
      "|     52|               4924.38|\n",
      "|     13|     5036.950000000001|\n",
      "+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows\n",
    "df_filtered = df.filter(df[\"user_id\"] > 10)\n",
    "\n",
    "# Group by and aggregate\n",
    "df_grouped = df.groupBy(\"user_id\").agg(F.sum(\"transaction_amount\").alias(\"sum_transaction_amount\"))\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c1e244-8840-4c09-b92d-b54fdd9ac779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|user_id|count(1)|\n",
      "+-------+--------+\n",
      "|     31|       7|\n",
      "|     85|       9|\n",
      "|     65|      11|\n",
      "|     53|      11|\n",
      "|     78|       9|\n",
      "|     34|      17|\n",
      "|     81|       7|\n",
      "|     28|      21|\n",
      "|     76|       8|\n",
      "|     26|      10|\n",
      "|     27|       8|\n",
      "|     44|       9|\n",
      "|     12|       8|\n",
      "|     91|       7|\n",
      "|     22|      13|\n",
      "|     93|      14|\n",
      "|     47|       4|\n",
      "|      1|       9|\n",
      "|     52|       9|\n",
      "|     13|       9|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Queries: Register DataFrame as a temporary table and run SQL queries.\n",
    "\n",
    "# Register the DataFrame as a temporary table\n",
    "df.createOrReplaceTempView(\"my_table\")\n",
    "\n",
    "# Run a SQL query\n",
    "sql_df = spark.sql(\"SELECT user_id, COUNT(*) FROM my_table GROUP BY user_id\")\n",
    "sql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c90ff8-2afb-42fd-8b8b-a38f494b9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
